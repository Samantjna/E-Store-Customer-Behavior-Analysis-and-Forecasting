import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, KFold
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Embedding
from datetime import datetime, timedelta

# Isikeliame duomenis
df = pd.read_csv('ecommerce_customer_data_custom_ratios.csv', nrows=1000)

# Pasirenkame reikiamus duomenis
selected_features = ['Customer ID', 'Product Price', 'Quantity', 'Purchase Date']
df_selected = df[selected_features]

# Konvertuojama į datetime formatą
df_selected['Purchase Date'] = pd.to_datetime(df_selected['Purchase Date'])
df_selected['Year'] = df_selected['Purchase Date'].dt.year
df_selected['Month'] = df_selected['Purchase Date'].dt.month
df_selected['Day'] = df_selected['Purchase Date'].dt.day
df_selected['Hour'] = df_selected['Purchase Date'].dt.hour
df_selected['Minute'] = df_selected['Purchase Date'].dt.minute

# Sukuriame naują stulpelį (paskutinė diena kada pirko)
df_selected.sort_values(by=['Customer ID', 'Purchase Date'], inplace=True)
df_selected['Previous Purchase'] = df_selected.groupby('Customer ID')['Purchase Date'].shift(1)
df_selected['Time Since Last Purchase'] = (df_selected['Purchase Date'] - df_selected['Previous Purchase']).dt.total_seconds() / 3600.0

# Pašaliname NaN reikšmes iš naujo stulpelio
df_selected.fillna(0, inplace=True)

# Sugrupuojame pirkimus pagal metus, menesius ir kliento ID
df_grouped = df_selected.groupby(['Year', 'Month', 'Customer ID']).agg({'Quantity': 'sum', 'Time Since Last Purchase': 'mean'}).reset_index()

# Naudojame Scaleri
scaler = MinMaxScaler(feature_range=(0, 1))
df_grouped['Scaled Quantity'] = scaler.fit_transform(df_grouped['Quantity'].values.reshape(-1, 1))

# Paruošiame mokymo ir testavimo rinkinius
look_back = 12
X, Y = [], []
for i in range(look_back, len(df_grouped)):
    X.append(df_grouped.iloc[i - look_back:i][['Scaled Quantity', 'Time Since Last Purchase']].values)
    Y.append(df_grouped.iloc[i]['Scaled Quantity'])
X, Y = np.array(X), np.array(Y)
X = np.reshape(X, (X.shape[0], X.shape[1], 2))

# KFolds for cross-validation (nezinau kaip lietuviskai)
kf = KFold(n_splits=10, shuffle=True, random_state=42)  #n_split tarp 5 ir 10 ("abu variantai isbandyti")

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    Y_train, Y_test = Y[train_index], Y[test_index]

    # GRU modelis
    model = Sequential([
        GRU(units=64, return_sequences=True, input_shape=(X_train.shape[1], 2)),
        GRU(units=64),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    #("optimizer 'adam' ir 'rmsrop' isbandyti")

    # Treniruojame modeli
    model.fit(X_train, Y_train, epochs=33, batch_size=34, validation_data=(X_test, Y_test), verbose=1)
    #("epochos isbandytos, batch_size 13,34,64 isbandyti")

    # Spejimas
    predictions = model.predict(X_test)

    # Atstatomas orginalus mastelis
    predictions = scaler.inverse_transform(predictions)
    Y_test = scaler.inverse_transform(Y_test.reshape(-1, 1))

    # Apskaičiuojame RMSE ir R2
    rmse = np.sqrt(mean_squared_error(Y_test, predictions))
    r2 = r2_score(Y_test, predictions)
    print("R2:", r2)     #0.9 ar auksciau
    print("RMSE:", rmse) #Kuo arciau 0 tuo geriau

    # Atvaizduoti rezultatus
    plt.plot(Y_test, label='Pagal faktą')
    plt.plot(predictions, label='Prognozė')
    plt.xlabel('Mėnesis')
    plt.ylabel('Kiekis')
    plt.title('Faktiniai ir prognozuojami pirkimai')
    plt.legend()
    plt.show()
